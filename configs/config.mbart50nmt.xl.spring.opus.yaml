name: baseline+smart_init
model: facebook/mbart-large-50-many-to-many-mmt

# <--------------
# Linearizations
# Comment DFS and uncomment the relevant block if you want to use a different linearization scheme

# DFS
penman_linearization: True
use_pointer_tokens: True
raw_graph: False

# BFS
# penman_linearization: False
# use_pointer_tokens: True
# raw_graph: False

# PENMAN
# penman_linearization: False
# use_pointer_tokens: True
# raw_graph: False

# BART baseline
# penman_linearization: False
# use_pointer_tokens: True
# raw_graph: False

remove_wiki: False
dereify: False
collapse_name_ops: False

# Hparams
my_model: True
batch_size: 1250
beam_size: 5
dropout: 0.25
attention_dropout: 0.0
smart_init: True
eval_every: 1000
accum_steps: 1
nproc_per_node: 4
warmup_steps: 1
training_steps: 30000
weight_decay: 0.004
grad_norm: 2.5
scheduler: constant
learning_rate: 0.00005
max_epochs: 12
save_checkpoints: True
log_wandb: False
warm_start: True
use_recategorization: False
best_loss: False
remove_longer_than: 1024
seed: 19940117

# <------------------
# Data: replace DATA below with the root of your AMR 2/3 release folder
train: /apdcephfs/share_916081/jcykcai/nonono/amr_2-four_translations/amrs/training/spring.opus/*.txt
dev: /apdcephfs/share_916081/jcykcai/nonono/amr_2-four_translations/amrs/dev/opus/*.txt
test: /apdcephfs/share_916081/jcykcai/nonono/amr_2-four_translations/amrs/test/*.txt
